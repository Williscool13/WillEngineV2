#version 460

#include "scene.glsl"
#include "gtao.glsl"

layout(local_size_x = 16, local_size_y = 16) in;

// layout (std140, set = 0, binding = 0) uniform SceneData - scene.glsl

layout (set = 1, binding = 0) uniform sampler2D prefilteredDepth;
layout (set = 1, binding = 1) uniform sampler2D normalBuffer;
layout (r8, set = 1, binding = 2) uniform image2D aoOutput;
layout (r8, set = 1, binding = 3) uniform image2D edgeDataOutput;
layout (rgba8, set = 1, binding = 4) uniform image2D debugImage;


#define XE_HILBERT_LEVEL 6u
#define XE_HILBERT_WIDTH (1u << XE_HILBERT_LEVEL)
#define XE_HILBERT_AREA (XE_HILBERT_WIDTH * XE_HILBERT_WIDTH)

#define XE_GTAO_PI                (3.1415926535897932384626433832795)
#define XE_GTAO_PI_HALF             (1.5707963267948966192313216916398)

#define XE_GTAO_SLICE_COUNT_LOW                 1.0f
#define XE_GTAO_SLICE_COUNT_MEDIUM              2.0f
#define XE_GTAO_SLICE_COUNT_HIGH                3.0f
#define XE_GTAO_SLICE_COUNT_ULTRA               9.0f

#define XE_GTAO_STEPS_PER_SLICE_COUNT_LOW       2.0f
#define XE_GTAO_STEPS_PER_SLICE_COUNT_MEDIUM    2.0f
#define XE_GTAO_STEPS_PER_SLICE_COUNT_HIGH      3.0f
#define XE_GTAO_STEPS_PER_SLICE_COUNT_ULTRA     3.0f

#define XE_GTAO_OCCLUSION_TERM_SCALE            1.5f

// http://h14s.p5r.org/2012/09/0x5f3759df.html, [Drobot2014a] Low Level Optimizations for GCN, https://blog.selfshadow.com/publications/s2016-shading-course/activision/s2016_pbs_activision_occlusion.pdf slide 63
float XeGTAO_FastSqrt(float x)
{
    return uintBitsToFloat(0x1fbd1df5 + (floatBitsToUint(x) >> 1));
}

// input [-1, 1] and output [0, PI], from https://seblagarde.wordpress.com/2014/12/01/inverse-trigonometric-functions-gpu-optimization-for-amd-gcn-architecture/
float XeGTAO_FastACos(float inX)
{
    const float PI = 3.141593;
    const float HALF_PI = 1.570796;
    float x = abs(inX);
    float res = -0.156583 * x + HALF_PI;
    res *= XeGTAO_FastSqrt(1.0 - x);
    return (inX >= 0) ? res : PI - res;
}

uint hilbertIndex(uint posX, uint posY)
{
    uint index = 0u;
    for (uint curLevel = XE_HILBERT_WIDTH/2u; curLevel > 0u; curLevel /= 2u)
    {
        uint regionX = (posX & curLevel) > 0u ? 1u : 0u;
        uint regionY = (posY & curLevel) > 0u ? 1u : 0u;
        index += curLevel * curLevel * ((3u * regionX) ^ regionY);
        if (regionY == 0u)
        {
            if (regionX == 1u)
            {
                posX = uint(XE_HILBERT_WIDTH - 1u) - posX;
                posY = uint(XE_HILBERT_WIDTH - 1u) - posY;
            }

            uint temp = posX;
            posX = posY;
            posY = temp;
        }
    }
    return index;
}

vec2 spatioTemporalNoise(ivec2 pixCoord, uint temporalIndex)// without TAA, temporalIndex is always 0
{
    uint index = hilbertIndex(uint(pixCoord.x), uint(pixCoord.y));
    index += 288u * (temporalIndex % 64u);
    return vec2(fract(0.5 + index * vec2(0.75487766624669276005, 0.5698402909980532659114)));
}

vec4 calculateDepthEdges(const float centerZ, const float leftZ, const float rightZ, const float topZ, const float bottomZ)
{
    vec4 edgesLRTB = vec4(leftZ, rightZ, topZ, bottomZ) - vec4(centerZ);

    float slopeLR = (edgesLRTB.y - edgesLRTB.x) * 0.5;
    float slopeTB = (edgesLRTB.w - edgesLRTB.z) * 0.5;
    vec4 edgesLRTBSlopeAdjusted = edgesLRTB + vec4(slopeLR, -slopeLR, slopeTB, -slopeTB);
    edgesLRTB = min(abs(edgesLRTB), abs(edgesLRTBSlopeAdjusted));

    return clamp((1.25 - edgesLRTB / (centerZ * 0.011)), 0, 1);;
}

vec3 cheapReconstructViewSpacePosition(vec2 uv, float viewspaceDepth)
{
    vec3 ret;
    ret.xy = (pushConstants.ndcToViewMul * uv.xy + pushConstants.ndcToViewAdd) * viewspaceDepth;
    ret.z = -viewspaceDepth;
    return ret;
}


vec4 reconstructViewSpacePosition(vec2 uv, float viewDepth) {
    float ndcDepth = pushConstants.depthLinearizeAdd - (pushConstants.depthLinearizeMult / viewDepth);
    vec2 ndc = uv * 2.0 - 1.0;
    vec4 positionVS = sceneData.invProjection * vec4(ndc, ndcDepth, 1.0);

    positionVS /= positionVS.w;
    return positionVS;
}

void outputWorkingTerm(ivec2 screenPos, float visibility, vec3 bentNormal, image2D outputImage){
    visibility = clamp(visibility / XE_GTAO_OCCLUSION_TERM_SCALE, 0, 1);
    imageStore(outputImage, screenPos, vec4(visibility + 0.5f / 255.0f));
}

mat3 adjugate(mat4 m) {
    return mat3(
    cross(m[1].xyz, m[2].xyz),
    cross(m[2].xyz, m[0].xyz),
    cross(m[0].xyz, m[1].xyz)
    );

}

void main() {
    const ivec2 screenPos = ivec2(gl_GlobalInvocationID.xy);

    if (screenPos.x > sceneData.renderTargetSize.x || screenPos.y > sceneData.renderTargetSize.y) {
        return;
    }

    vec2 uv = (vec2(screenPos) + 0.5) * sceneData.texelSize;

    vec4 valuesUL = textureGather(prefilteredDepth, uv, 0);
    vec4 valuesBR = textureGatherOffset(prefilteredDepth, uv, ivec2(1,1), 0);
    float viewSpaceZM = valuesUL.y;
    const float viewSpaceZL = valuesUL.x;
    const float viewSpaceZR = valuesUL.z;
    const float viewSpaceZT = valuesBR.z;
    const float viewSpaceZB = valuesBR.x;

    vec4 edges  = calculateDepthEdges(viewSpaceZM, viewSpaceZL, viewSpaceZR, viewSpaceZT, viewSpaceZB);
    float packedEdges = XeGTAO_PackEdges(edges);
    imageStore(edgeDataOutput, screenPos, vec4(packedEdges));

    float minEdge = min(min(edges.x, edges.y), min(edges.z, edges.w));

    if (pushConstants.debug == 2){
        imageStore(debugImage, screenPos, vec4(vec3(minEdge), 1.0f));
        return;
    }

    // Get view space normal by sampling normal buffer and converting from world to view (code not relevant)
    vec3 worldNormal = texture(normalBuffer, uv).rgb;
    vec3 viewNormal = adjugate(sceneData.view) * worldNormal;

    if (pushConstants.debug == 2){
        imageStore(debugImage, screenPos, vec4(viewNormal, 1.0f));
        return;
    }

    // Per Intel: Move center pixel slightly towards camera to avoid imprecision artifacts due to depth buffer imprecision; offset depends on depth texture format used
    viewSpaceZM = viewSpaceZM * 0.998f;

    //vec3 vPos = cheapReconstructViewSpacePosition(uv, viewSpaceZM);
    vec4 vPosAlt = reconstructViewSpacePosition(uv, viewSpaceZM);
    vec3 vPos = vPosAlt.xyz;
    vec3 viewVec = normalize(-vPos);

    // debug world pos
    if (pushConstants.debug == 3){
        vec3 worldPos = (sceneData.invView * vPosAlt).xyz;
        imageStore(debugImage, screenPos, vec4(worldPos / 1000.0f, 1.0f));
        return;
    }

    // Per Intel
    // prevents normals that are facing away from the view vector - xeGTAO struggles with extreme cases, but in Vanilla it seems rare so it's disabled by default
     viewNormal = normalize(viewNormal + max(0, -dot(viewNormal, viewVec)) * viewVec);


    const float effectRadius = pushConstants.effectRadius * pushConstants.radiusMultiplier;
    const float sampleDistributionPower = pushConstants.sampleDistributionPower;
    const float thinOccluderCompensation = pushConstants.thinOccluderCompensation;
    const float falloffRange = pushConstants.effectFalloffRange * effectRadius;

    const float falloffFrom = effectRadius * (1 - pushConstants.effectFalloffRange);

    // fadeout precompute optimisation
    const float falloffMul = -1.0 / (falloffRange);
    const float falloffAdd = falloffFrom / (falloffRange) + 1.0;

    float visibility = 0;
    vec3 bentNormal = vec3(0.0f);

    {
        // NOISE
        vec2 noise = spatioTemporalNoise(screenPos, pushConstants.noiseIndex);
        float noiseSlice = noise.x;
        float noiseSample = noise.y;

        const float pixelTooCloseThreshold  = 1.3;
        const vec2 pixelDirRBViewspaceSizeAtCenterZ = viewSpaceZM.xx * pushConstants.ndcToViewMul_x_PixelSize;

        float screenspaceRadius = effectRadius / pixelDirRBViewspaceSizeAtCenterZ.x;

        visibility += clamp((10 - screenspaceRadius)/100, 0, 1) * 0.5;

        if (screenspaceRadius < pixelTooCloseThreshold)
        {
            visibility = 1;
            visibility = clamp(visibility / XE_GTAO_OCCLUSION_TERM_SCALE, 0, 1);
            if (pushConstants.debug == 4){
                imageStore(debugImage, screenPos, vec4(vec3(visibility), 1.0f));
                return;
            }

            imageStore(aoOutput, screenPos, vec4(visibility));
            // todo: look at how this will return 1/1.5 instead of 1 for visibility always?
            // todo: (bent normal) need to write `viewNormal` value to the buffer (i.e. no change to trajectory of normal)
            return;
        }

        const float minS = pixelTooCloseThreshold / screenspaceRadius;

        float sliceCount = XE_GTAO_SLICE_COUNT_ULTRA;
        float stepsPerSlice = XE_GTAO_STEPS_PER_SLICE_COUNT_ULTRA;

        for (float slice = 0; slice < sliceCount; slice++){
            float sliceK = (slice+noiseSlice) / sliceCount;
            // lines 5, 6 from the paper
            float phi = sliceK * XE_GTAO_PI;
            float cosPhi = cos(phi);
            float sinPhi = sin(phi);
            vec2 omega = vec2(cosPhi, sinPhi);//lpfloat2 on omega causes issues with big radii

            // convert to screen units (pixels) for later use
            omega *= screenspaceRadius;

            // line 8 from the paper
            const vec3 directionVec = vec3(cosPhi, sinPhi, 0);

            // line 9 from the paper
            const vec3 orthoDirectionVec = directionVec - (dot(directionVec, viewVec) * viewVec);

            // line 10 from the paper
            //axisVec is orthogonal to directionVec and viewVec, used to define projectedNormal
            const vec3 axisVec = normalize(cross(orthoDirectionVec, viewVec));

            // alternative line 9 from the paper
            // float3 orthoDirectionVec = cross( viewVec, axisVec );

            // line 11 from the paper
            vec3 projectedNormalVec = viewNormal - axisVec * dot(viewNormal, axisVec);

            // line 13 from the paper
            float signNorm = sign(dot(orthoDirectionVec, projectedNormalVec));

            // line 14 from the paper
            float projectedNormalVecLength = length(projectedNormalVec);
            float cosNorm = clamp(dot(projectedNormalVec, viewVec) / projectedNormalVecLength, 0, 1);

            // line 15 from the paper
            float n = signNorm * XeGTAO_FastACos(cosNorm);

            // this is a lower weight target; not using -1 as in the original paper because it is under horizon, so a 'weight' has different meaning based on the normal
            const float lowHorizonCos0  = cos(n+XE_GTAO_PI_HALF);
            const float lowHorizonCos1  = cos(n-XE_GTAO_PI_HALF);

            // lines 17, 18 from the paper, manually unrolled the 'side' loop
            float horizonCos0           = lowHorizonCos0;//-1;
            float horizonCos1           = lowHorizonCos1;//-1;

            for (float step = 0; step < stepsPerSlice; step++) {
                // R1 sequence (http://extremelearning.com.au/unreasonable-effectiveness-of-quasirandom-sequences/)
                const float stepBaseNoise = (slice + step * stepsPerSlice) * 0.6180339887498948482;// <- this should unroll
                float stepNoise = fract(noiseSample + stepBaseNoise);

                // approx line 20 from the paper, with added noise
                float s = (step+stepNoise) / (stepsPerSlice);// + (lpfloat2)1e-6f);

                // additional distribution modifier
                s       = pow(s, sampleDistributionPower);

                // avoid sampling center pixel
                s       += minS;

                // approx lines 21-22 from the paper, unrolled
                vec2 sampleOffset = s * omega;

                float sampleOffsetLength = length(sampleOffset);

                const int XE_GTAO_DEPTH_MIP_LEVELS = 5;
                // note: when sampling, using point_point_point or point_point_linear sampler works, but linear_linear_linear will cause unwanted interpolation between neighbouring depth values on the same MIP level!
                const float mipLevel    = clamp(log2(sampleOffsetLength) - pushConstants.depthMipSamplingOffset, 0, XE_GTAO_DEPTH_MIP_LEVELS);

                // Snap to pixel center (more correct direction math, avoids artifacts due to sampling pos not matching depth texel center - messes up slope - but adds other
                // artifacts due to them being pushed off the slice). Also use full precision for high res cases.
                sampleOffset = round(sampleOffset) * sceneData.texelSize;

                vec2 sampleScreenPos0 = uv + sampleOffset;
                float  SZ0 = textureLod(prefilteredDepth, sampleScreenPos0, mipLevel).r;
                //vec3 samplePos0 = cheapReconstructViewSpacePosition(sampleScreenPos0, SZ0);
                vec3 samplePos0 = reconstructViewSpacePosition(sampleScreenPos0, SZ0).xyz;

                vec2 sampleScreenPos1 = uv - sampleOffset;
                float  SZ1 = textureLod(prefilteredDepth, sampleScreenPos1, mipLevel).r;
                //vec3 samplePos1 = cheapReconstructViewSpacePosition(sampleScreenPos1, SZ1);
                vec3 samplePos1 = reconstructViewSpacePosition(sampleScreenPos1, SZ1).xyz;

                vec3 sampleDelta0     = (samplePos0 - vec3(vPos));// using lpfloat for sampleDelta causes precision issues
                vec3 sampleDelta1     = (samplePos1 - vec3(vPos));// using lpfloat for sampleDelta causes precision issues
                float sampleDist0     = length(sampleDelta0);
                float sampleDist1     = length(sampleDelta1);

                // approx lines 23, 24 from the paper, unrolled
                vec3 sampleHorizonVec0 = (sampleDelta0 / sampleDist0);
                vec3 sampleHorizonVec1 = (sampleDelta1 / sampleDist1);


                // this is our own thickness heuristic that relies on sooner discarding samples behind the center
                float falloffBase0    = length(vec3(sampleDelta0.x, sampleDelta0.y, sampleDelta0.z * (1+thinOccluderCompensation)));
                float falloffBase1    = length(vec3(sampleDelta1.x, sampleDelta1.y, sampleDelta1.z * (1+thinOccluderCompensation)));
                float weight0         = clamp(falloffBase0 * falloffMul + falloffAdd, 0, 1);
                float weight1         = clamp(falloffBase1 * falloffMul + falloffAdd, 0, 1);

                // sample horizon cos
                float shc0 = dot(sampleHorizonVec0, viewVec);
                float shc1 = dot(sampleHorizonVec1, viewVec);

                // discard unwanted samples
                shc0 = mix(lowHorizonCos0, shc0, weight0);// this would be more correct but too expensive: cos(lerp( acos(lowHorizonCos0), acos(shc0), weight0 ));
                shc1 = mix(lowHorizonCos1, shc1, weight1);// this would be more correct but too expensive: cos(lerp( acos(lowHorizonCos1), acos(shc1), weight1 ));


                // this is a version where thicknessHeuristic is completely disabled
                horizonCos0 = max(horizonCos0, shc0);
                horizonCos1 = max(horizonCos1, shc1);
            }

            #if 1// I can't figure out the slight overdarkening on high slopes, so I'm adding this fudge - in the training set, 0.05 is close (PSNR 21.34) to disabled (PSNR 21.45)
            projectedNormalVecLength = mix(projectedNormalVecLength, 1, 0.05);
            #endif

            // line ~27, unrolled
            float h0 = -XeGTAO_FastACos(horizonCos1);
            float h1 = XeGTAO_FastACos(horizonCos0);
            float iarc0 = (cosNorm + 2 * h0 * sin(n) - cos(2 * h0 - n)) / 4;
            float iarc1 = (cosNorm + 2 * h1 * sin(n) - cos(2 * h1 - n)) / 4;
            float localVisibility = projectedNormalVecLength * (iarc0+iarc1);
            visibility += localVisibility;

            // todo: uncomment and fix if outputting bent normals
            // see "Algorithm 2 Extension that computes bent normals b."
            // lpfloat t0 = (6*sin(h0-n)-sin(3*h0-n)+6*sin(h1-n)-sin(3*h1-n)+16*sin(n)-3*(sin(h0+n)+sin(h1+n)))/12;
            // lpfloat t1 = (-cos(3 * h0-n)-cos(3 * h1-n) +8 * cos(n)-3 * (cos(h0+n) +cos(h1+n)))/12;
            // lpfloat3 localBentNormal = lpfloat3(directionVec.x * (lpfloat)t0, directionVec.y * (lpfloat)t0, -lpfloat(t1) );
            // localBentNormal = (lpfloat3)mul(XeGTAO_RotFromToMatrix(lpfloat3(0, 0, -1), viewVec), localBentNormal ) * projectedNormalVecLength;
            // bentNormal += localBentNormal;
        }

        visibility /= sliceCount;
        visibility = pow(visibility, pushConstants.finalValuePower);
        visibility = max(0.03, visibility);// disallow total occlusion (which wouldn't make any sense anyhow since pixel is visible but also helps with packing bent normals)

        // todo (bent normal)
        // bentNormal = normalize(bentNormal) ;
    }

    // todo (bent normal)
    visibility = clamp(visibility / XE_GTAO_OCCLUSION_TERM_SCALE, 0, 1);
    if (pushConstants.debug == 4){
        imageStore(debugImage, screenPos, vec4(vec3(visibility), 1.0f));
        return;
    }

    imageStore(aoOutput, screenPos, vec4(visibility));
}
