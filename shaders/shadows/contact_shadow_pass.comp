#version 460

#include "scene.glsl"

#define WAVE_SIZE 64

layout(local_size_x = WAVE_SIZE, local_size_y = 1, local_size_z = 1) in;

// layout (std140, set = 0, binding = 0) uniform SceneData - scene.glsl

layout (set = 1, binding = 0) uniform sampler2D depthImage;
layout (r8, set = 1, binding = 1) uniform image2D contactShadow;
layout (rgba8, set = 1, binding = 2) uniform image2D debugImage;

#define SAMPLE_COUNT 60

// Number of bilinear sample reads performed per-thread
#define READ_COUNT (SAMPLE_COUNT / WAVE_SIZE + 2)

// samples requires for hard shadow
#define HARD_SHADOW_SAMPLES 4
// shadow fade at shadow edges
#define FADE_OUT_SAMPLES 8

// Main camera depth bounds
#define NEAR_DEPTH_VALUE 1
#define FAR_DEPTH_VALUE 0

// Light VP dpeth bounds
#define DEPTH_BOUNDS vec2(0, 1)

#define USE_HALF_PIXEL_OFFSET 1

layout (push_constant) uniform PushConstants {
    float surfaceThickness;
    float bilinearThreshold;
    float shadowContrast;

    int bIgnoreEdgePixels;
    int bUsePrecisionOffset;
    int bilinearSamplingOffsetMode;

    vec2 depthBounds;
    int bUseEarlyOut;

    int debugMode;

    ivec2 waveOffset;
    vec4 lightCoordinate;

} pushConstants;

shared float DepthData[READ_COUNT * WAVE_SIZE];
shared bool LdsEarlyOut;

void ComputeWavefrontExtents(ivec2 waveOffset, vec4 lightCoordinate, ivec3 inGroupID, uint inGroupThreadID,
out vec2 outDeltaXY, out vec2 outPixelXY, out float outPixelDistance, out bool outMajorAxisX)
{
    ivec2 xy = inGroupID.yz * WAVE_SIZE + waveOffset.xy;

    // Integer light position / fractional component
    vec2 light_xy = floor(lightCoordinate.xy) + 0.5;
    vec2 light_xy_fraction = lightCoordinate.xy - light_xy;
    bool reverse_direction = lightCoordinate.w > 0.0;

    ivec2 sign_xy = ivec2(sign(vec2(xy)));
    bool horizontal = abs(xy.x + sign_xy.y) < abs(xy.y - sign_xy.x);

    ivec2 axis;
    axis.x = horizontal ? (+sign_xy.y) : (0);
    axis.y = horizontal ? (0) : (-sign_xy.x);

    // Apply wave offset
    xy = axis * int(inGroupID.x) + xy;
    vec2 xy_f = vec2(xy);

    // For interpolation to the light center, we only really care about the larger of the two axis
    bool x_axis_major = abs(xy_f.x) > abs(xy_f.y);
    float major_axis = x_axis_major ? xy_f.x : xy_f.y;

    float major_axis_start = abs(major_axis);
    float major_axis_end = abs(major_axis) - float(WAVE_SIZE);

    float ma_light_frac = x_axis_major ? light_xy_fraction.x : light_xy_fraction.y;
    ma_light_frac = major_axis > 0.0 ? -ma_light_frac : ma_light_frac;

    // Back in to screen direction
    vec2 start_xy = xy_f + light_xy;

    // For the very inner most ring, we need to interpolate to a pixel centered UV,
    // so the UV->pixel rounding doesn't skip output pixels
    vec2 end_xy = mix(lightCoordinate.xy, start_xy, (major_axis_end + ma_light_frac) / (major_axis_start + ma_light_frac));

    // The major axis should be a round number
    vec2 xy_delta = (start_xy - end_xy);

    // Inverse the read order when reverse direction is true
    float thread_step = float(inGroupThreadID ^ (reverse_direction ? 0u : (WAVE_SIZE - 1u)));

    vec2 pixel_xy = mix(start_xy, end_xy, thread_step / float(WAVE_SIZE));
    float pixel_distance = major_axis_start - thread_step + ma_light_frac;

    outPixelXY = pixel_xy;
    outPixelDistance = pixel_distance;
    outDeltaXY = xy_delta;
    outMajorAxisX = x_axis_major;
}


bool EarlyOutPixel(vec2 depthBounds, vec2 pixel_xy, float depth)
{
    //OPTIONAL TODO; customize this function to return true if the pixel should early-out for custom reasons. E.g., A shadow map pass already found the pixel was in shadow / backfaced, etc.
    // Recommended to keep this code very simple!

    // Example:
    // return inParameters.CustomShadowMapTerm[pixel_xy] == 0;

    // (void)pixel_xy;	//unused by this implementation, avoid potential compiler warning.

    // The compiled code will be more optimal if the 'depth' value is not referenced.
    return depth >= depthBounds.y || depth <= depthBounds.x;
}

void main() {
    vec2 xy_delta;
    vec2 pixel_xy;
    float pixel_distance;
    bool x_axis_major;

    ComputeWavefrontExtents(pushConstants.waveOffset, pushConstants.lightCoordinate, ivec3(gl_WorkGroupID), gl_LocalInvocationID.x,
    xy_delta, pixel_xy, pixel_distance, x_axis_major);

    // Read in the depth values
    float sampling_depth[READ_COUNT];
    float shadowing_depth[READ_COUNT];
    float depth_thickness_scale[READ_COUNT];
    float sample_distance[READ_COUNT];

    const float direction = -pushConstants.lightCoordinate.w;
    const float z_sign = NEAR_DEPTH_VALUE > FAR_DEPTH_VALUE ? -1 : +1;

    int i;
    bool is_edge = false;
    bool skip_pixel = false;
    vec2 write_xy = floor(pixel_xy);

    for (i = 0; i < READ_COUNT; i++)
    {
        // We sample depth twice per pixel per sample, and interpolate with an edge detect filter
        // Interpolation should only occur on the minor axis of the ray - major axis coordinates should be at pixel centers
        vec2 read_xy = floor(pixel_xy);
        float minor_axis = x_axis_major ? pixel_xy.y : pixel_xy.x;

        // If a pixel has been detected as an edge, then optionally (inParameters.IgnoreEdgePixels) don't include it in the shadow
        const float edge_skip = 1e20;// if edge skipping is enabled, apply an extreme value/blend on edge samples to push the value out of range

        vec2 depths;
        float bilinear = fract(minor_axis) - 0.5;

        #if USE_HALF_PIXEL_OFFSET
        read_xy += 0.5;
        #endif

        // HLSL enforces that a pixel offset is a compile-time constant, which isn't strictly required (and can sometimes be a bit faster)
        // So this fallback will use a manual uv offset instead
        int bias = bilinear > 0 ? 1 : -1;
        vec2 offset_xy = vec2(x_axis_major ? 0 : bias, x_axis_major ? bias : 0);

        depths.x = textureLod(depthImage, read_xy * sceneData.texelSize, 0).r;
        depths.y = textureLod(depthImage, (read_xy + offset_xy) * sceneData.texelSize, 0).r;

        // Depth thresholds (bilinear/shadow thickness) are based on a fractional ratio of the difference between sampled depth and the far clip depth
        depth_thickness_scale[i] = abs(FAR_DEPTH_VALUE - depths.x);

        // If depth variance is more than a specific threshold, then just use point filtering
        bool use_point_filter = abs(depths.x - depths.y) > depth_thickness_scale[i] * pushConstants.bilinearThreshold;

        // Store for debug output when inParameters.DebugOutputEdgeMask is true
        if (i == 0) {
            is_edge = use_point_filter;
        }

        if (pushConstants.bilinearSamplingOffsetMode == 1)
        {
            bilinear = use_point_filter ? 0 : bilinear;
            //both shadow depth and starting depth are the same in this mode, unless shadow skipping edges
            sampling_depth[i] = mix(depths.x, depths.y, abs(bilinear));
            shadowing_depth[i] = (pushConstants.bIgnoreEdgePixels == 1 && use_point_filter) ? edge_skip : sampling_depth[i];
        }
        else
        {
            // The pixel starts sampling at this depth
            sampling_depth[i] = depths.x;

            float edge_depth = pushConstants.bIgnoreEdgePixels == 1 ? edge_skip : depths.x;
            // Any sample in this wavefront is possibly interpolated towards the bilinear sample
            // So use should use a shadowing depth that is further away, based on the difference between the two samples
            float shadow_depth = depths.x + abs(depths.x - depths.y) * z_sign;

            // Shadows cast from this depth
            shadowing_depth[i] = use_point_filter ? edge_depth : shadow_depth;
        }

        // Store for later
        sample_distance[i] = pixel_distance + (WAVE_SIZE * i) * direction;

        // Iterate to the next pixel along the ray. This will be WAVE_SIZE pixels along the ray...
        pixel_xy += xy_delta * direction;
    }

    // Using early out, and no debug mode is enabled?
    //    if (pushConstants.bUseEarlyOut == 1 && (inParameters.DebugOutputWaveIndex == false && inParameters.DebugOutputThreadIndex == false && inParameters.DebugOutputEdgeMask == false))
    //    {
    //        // read the depth of the pixel we are shadowing, and early-out
    //        // The compiler will typically rearrange this code to put it directly after the first depth read
    //        skip_pixel = EarlyOutPixel(DEPTH_BOUNDS, write_xy, sampling_depth[0]);
    //
    //        // are all threads in this wave out of bounds?
    //        bool early_out = WaveActiveAnyTrue(!skip_pixel) == false;
    //
    //        // WaveGetLaneCount returns the hardware wave size
    //        if (WaveGetLaneCount() == WAVE_SIZE)
    //        {
    //            // Optimal case:
    //            // If each wavefront is just a single wave, then we can trivially early-out.
    //            if (early_out == true){
    //                return;
    //            }
    //
    //        }
    //        else
    //        {
    //            // This wavefront is made up of multiple small waves, so we need to coordinate them for all to early-out together.
    //            // Doing this can make the worst case (all pixels drawn) a bit more expensive (~15%), but the best-case (all early-out) is typically 2-3x better.
    //            LdsEarlyOut = true;
    //
    //            memoryBarrierShared();
    //            barrier();
    //
    //            if (early_out == false){
    //                LdsEarlyOut = false;
    //            }
    //
    //
    //            memoryBarrierShared();
    //            barrier();
    //
    //            if (LdsEarlyOut)
    //            return;
    //        }
    //    }

    // Write the shadow depths to LDS
    for (i = 0; i < READ_COUNT; i++)
    {
        // Perspective correct the shadowing depth, in this space, all light rays are parallel
        float stored_depth = (shadowing_depth[i] - pushConstants.lightCoordinate.z) / sample_distance[i];

        if (i != 0)
        {
            // For pixels within sampling distance of the light, it is possible that sampling will
            // overshoot the light coordinate for extended reads. We want to ignore these samples
            stored_depth = sample_distance[i] > 0 ? stored_depth : 1e10;
        }

        // Store the depth values in groupshared
        int idx = (i * WAVE_SIZE) + int(gl_LocalInvocationID.x);
        DepthData[idx] = stored_depth;
    }

    // Sync wavefronts now groupshared DepthData is written
    memoryBarrierShared();
    barrier();

    // If the starting depth isn't in depth bounds, then we don't need a shadow
    if (skip_pixel){
        return;
    }

    float start_depth = sampling_depth[0];

    // lerp away from far depth by a tiny fraction?
    if (pushConstants.bUsePrecisionOffset == 1){
        start_depth = mix(start_depth, FAR_DEPTH_VALUE, -1.0 / 0xFFFF);
    }

    // perspective correct the depth
    start_depth = (start_depth - pushConstants.lightCoordinate.z) / sample_distance[0];

    // Start by reading the next value
    int sample_index = int(gl_LocalInvocationID.x) + 1;

    vec4 shadow_value = vec4(1.0f);
    float hard_shadow = 1;

    // This is the inverse of how large the shadowing window is for the projected sample data.
    // All values in the LDS sample list are scaled by 1.0 / sample_distance, such that all light directions become parallel.
    // The multiply by sample_distance[0] here is to compensate for the projection divide in the data.
    // The 1.0 / inParameters.SurfaceThickness is to adjust user selected thickness. So a 0.5% thickness will scale depth values from [0,1] to [0,200]. The shadow window is always 1 wide.
    // 1.0 / depth_thickness_scale[0] is because SurfaceThickness is percentage of remaining depth between the sample and the far clip - not a percentage of the full depth range.
    // The min() function is to make sure the window is a minimum width when very close to the light. The +direction term will bias the result so the pixel at the very center of the light is either fully lit or shadowed
    float depth_scale = min(sample_distance[0] + direction, 1.0 / pushConstants.surfaceThickness) * sample_distance[0] / depth_thickness_scale[0];

    start_depth = start_depth * depth_scale - z_sign;

    // The first number of hard shadow samples, a single pixel can produce a full shadow
    for (i = 0; i < HARD_SHADOW_SAMPLES; i++)
    {
        float depth_delta = abs(start_depth - DepthData[sample_index + i] * depth_scale);

        // We want to find the distance of the sample that is closest to the reference depth
        hard_shadow = min(hard_shadow, depth_delta);
    }

    // Brute force go!
    // The main shadow samples, averaged in to a set of 4 shadow values
    for (i = HARD_SHADOW_SAMPLES; i < SAMPLE_COUNT - FADE_OUT_SAMPLES; i++)
    {
        float depth_delta = abs(start_depth - DepthData[sample_index + i] * depth_scale);

        // Do the same as the hard_shadow code above, but this will accumulate to 4 separate values.
        // By using 4 values, the average shadow can be taken, which can help soften single-pixel shadows.
        shadow_value[i & 3] = min(shadow_value[i & 3], depth_delta);
    }

    // Final fade out samples
    for (i = SAMPLE_COUNT - FADE_OUT_SAMPLES; i < SAMPLE_COUNT; i++)
    {
        float depth_delta = abs(start_depth - DepthData[sample_index + i] * depth_scale);

        // Add the fade value to these samples
        const float fade_out = float(i + 1 - (SAMPLE_COUNT - FADE_OUT_SAMPLES)) / float((FADE_OUT_SAMPLES + 1) * 0.75);

        shadow_value[i & 3] = min(shadow_value[i & 3], depth_delta + fade_out);
    }

    // Apply the contrast value.
    // A value of 0 indicates a sample was exactly matched to the reference depth (and the result is fully shadowed)
    // We want some boost to this range, so samples don't have to exactly match to produce a full shadow.
    shadow_value = clamp(shadow_value * (pushConstants.shadowContrast) + (1 - pushConstants.shadowContrast), 0, 1);
    hard_shadow = clamp(hard_shadow * (pushConstants.shadowContrast) + (1 - pushConstants.shadowContrast), 0, 1);

    float result = 0;

    // Take the average of 4 samples, this is useful to reduces aliasing noise in the source depth, especially with long shadows.
    result = dot(shadow_value, vec4(0.25));

    // If the first samples are always producing a hard shadow, then compute this value separately.
    result = min(hard_shadow, result);

    //write the result
    {
        switch (pushConstants.debugMode){
            case 1:
            result = is_edge ? 1 : 0;
            break;
            case 2:
            result = (gl_LocalInvocationID.x / float(WAVE_SIZE));
            break;
            case 3:
            result = fract(ivec3(gl_WorkGroupID).x / float(WAVE_SIZE));
            break;
        }

        imageStore(debugImage, ivec2(write_xy), vec4(vec3(result), 1.0f));
    }
}
